
<p>
  With the development of intelligent technology, robots are gradually expanding from the traditional industrial field to a wider range of application scenarios, where it is becoming increasingly important to enable robots to perform accurate navigation in complex unstructured and dynamically-changing environments. Recently, Deep Learning (DL) has greatly enhanced the perception ability of the robotic system, and Deep Reinforcement Learning (DRL) and other learning-based methods have brought new opportunities for dealing with these problems. However, most learning-based methods depend on the simulation environment. How to transfer the algorithms trained in the simulation environment to the physical system has become the key to solving the problem.
</p>

<p>
  The goal of the competition is to find good sim2real methods. In the competition task, the robot needs to find 5 targets whose positions are randomly generated in the maze, and complete the activation in a specified order. In 3 minutes, the agent which finds 5 targets and activates them at the fastest and safe speed wins. The competition will be divided into two stages: in the first stage, the agent only needs to complete the above tasks in the simulation environment. We will select the agents with higher scores to participate in the second stage. In the second stage, we deploy the participating agents to the physical robot and test them in a real environment. At this stage, the agent needs to deal with the difference between the simulated robot actuator and the physical actuator, and the state difference caused by a different environment. The agent can adjust the model according to the feedback data and results.  
</p>
<p><a href="https://github.com/liushasha2021/EvalAI-CoG/blob/challenge/templates/a.gif">Demo Vidio</a></p>
<p><a href="https://github.com/DRL-CASIA/COG-sim2real-challenge">Github Baseline Algrithom</a></p>
<p><a href="https://github.com/DRL-CASIA/COG-sim2real-challenge/blob/main/CoG%20Challenge%20Rules1.3.pdf">CoG Challenge Rules(English Version)</a></p>
<p><a href="https://github.com/DRL-CASIA/COG-sim2real-challenge/blob/main/2022%20CoG%20RoboMaster%20Sim2Real%20Challenge%E8%A7%84%E5%88%99%E6%89%8B%E5%86%8C1.3.pdf">CoG Challenge Rules(中文版)</a></p>

<h5>Track</h5>
<h6>Track 1: complete information-based track.</h6>
<p>The state of the robot includes its position in the map, speed, image at the current time, and the target position (but it does not know the corresponding order, which can be determined only after detecting the visual label). The algorithm is required to output the speed command to control the robot.</p>

<h6>Track 2: image-based track</h6>
<p>The robot can obtain only the image and speed of the current time. The algorithm is required to output the speed command to control the robot.</p>
